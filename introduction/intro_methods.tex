\chapter{General Methodology}
\label{cha:methods_applied_in_genetic_studies_on_humans}

The investigation of underlying genetic architecture of human traits is limited to non-experimental studies and one can broadly distinguish between two types: twin studies and association studies.
Twin studies make use of monozygotic and dizygotic twin pairs to estimate the contribution of genetic and environmental components of a trait.
In contrast, association studies make use of recently developed molecular methods to identify specific genetic variation within the human genome associated with a specific trait.
Within this section I will describe commonly used methods in both twin and molecular based association studies.
I will further describe methods used to estimate heritability and genetic correlations.

\section{Twin Studies}
\label{sec:twin_based_studies}

Twins have always been of special interest to scholars.
Indeed, already Hippocrates has been reported to be interested in twins at around 5th century BCE\@.
While his original accounts are lost, the Roman politician and author Cicero described Hippocrates's observations of two ill brothers, suspected to be twins, with similar identical disease progression~\cite{Cicero44BC},
thus providing the first written account of a twin study.

Much later Francis Galton was one of the first persons to use twins in order to investigate the effect of genes and the environment on human behavior~\cite{Rende1990}.
However, only when~\citet{Simens1924} discovered the two distinct types of twins, namely \acrfull{mz} and \acrfull{dz} twins, twin studies became an established instrument in the investigation of genetic factors in humans.

MZ twins develop from a single fertilized egg and therefore share all of their genetic makeup.
On the other hand, \acrshort{dz} twins develop from two fertilized eggs and share on average 50\% of segregating genetic variants.
This distinction forms the basis of all twin studies and allows use of structural equations relating observed trait and theorized underlying genetic and environmental effects.

In addition, genetic effects can be further distinguished between additive genetic effects (A) which represent the accumulated effect of all individual alleles across the genome and dominant (D) effects which represents interaction on the same genetic locus.
Environmental components are differentiated into shared environment (C) and unique environment (E).
Therefore, the total variance of any particular trait is $V_P = A+D+C+E$.
Since one can assume different correlations between MZ ($r_{MZ}$) and DZ ($r_{DZ}$) twin pairs one can estimate components of $V_P$.

While the correlations between twins within C and E are the same in both MZ and DZ twins, namely $1$ and $0$, respectively,
MZ twins are assumed to have a correlation of $1$ for both A and D, while DZ pairs have a correlation of $\frac{1}{2}$ and $\frac{1}{4}$, on average respectively.
Therefore, differences within MZ twins can be attributed to E alone.
Further, when we assume that DZ and MZ twins are exposed to the same degree of similarity within their environment, the differences in similarity between MZ and DZ twins is an estimate of all the genetic contribution to the phenotypic variance (i.e. including additive, dominant, and epistatic effects).
This is also called Falconer's formula (see Formula~\ref{eq:falcon}) and can be used to approximate the broad sense heritability, also denoted as $H^2$:
\begin{align}
  H^2 &= 2(r_{MZ}-r_{DZ}) \label{eq:falcon} \\ 
  C &= r_{MZ} - H^2  \\
  E &= 1 - r_{MZ}  
\end{align}

However, while the above is attractive it its simplicity, today's twin studies use \acrfull{sem} to model genetic and environment effects.
SEM is more flexible in modeling specific hypotheses, such as testing for sex differences as well handling multivariate data~\cite{Rijsdijk2002}.
Furthermore, Falconer's method is not able to distinguish between additive and non-additive genetic factors.

Figure~\ref{fig:ace} displays such a classical path-based model.
Variables within a SEM can be separated into latent and observed variables.
Additive genetic (A), common environment (C) and unique environment (E) are latent variables.
These variables are not directly observed but are inferred from actual measured variables.
Observed variables are commonly displayed in cornered boxes.
The correlations among A and C are represented by the double headed arrows.
The causal paths $a$, $c$, and $e$ represent the effect of the components on the trait $T$, and the square of these estimates represent the variance accounted for by each of the corresponding latent factors.
However, effects of $D$ cannot be simultaneously estimated with $C$.

\begin{figure}[htpb]
  \centering
  \scalebox{0.6}{\input{introduction/figure/ACE.tex}}
  \caption[ACE Model]{
    Basic ACE model.
    This basic model contains the latent variables A, C and E for twin 1 and 2, as well as the observed variable T with the mean $\mu$.
    The model assumes a MZ and DZ twin correlation of $1$ and $0.5$ respectivly.
  }\label{fig:ace}
\end{figure}

The covariance matrix of the model in Figure~\ref{fig:ace} is therefore
\begin{equation}
  cov(MZ) = 
  \begin{pmatrix}
    a^2 + c^2 + e^2 & a^2 + c^2 \\
    a^2 + c^2 & a^2 + c^2 + e^2
  \end{pmatrix}
\end{equation}
and 
\begin{equation}
  cov(DZ) = 
  \begin{pmatrix}
    a^2 + c^2 + e^2 & \frac{1}{2}a^2 + c^2 \\
    \frac{1}{2}a^2 + c^2 & a^2 + c^2 + e^2
  \end{pmatrix}
\end{equation}
Modern SEM software is able to estimate parameters by minimising the goodness-of-fit statistic between the observed and predicted covariance matrices~\cite{Boker2011}.
Previously this has been done via a maximum-likelihood function.
However, commonly data contains missing values, thus the observed covariance matrix might not contain all information.
Therefore, many studies use the full information maximum-likelihood (FIML) function to estimate parameters.

Given the matrix $X$ of size $n\times p$, in which $n$ represent the number of subjects and $p$ the number of observed variables, then the $-2\log$ likelihood of a give row $i$ is
\begin{equation}\label{eq:fiml}
  \mathcal{L}_i = k_i \ln(2\pi) + \ln(|\sum_i|) + (X_i - M_i)\sum_i^{-1}(X_i -M_i)^{T} 
\end{equation}
in which $k_i$ is the count of non-missing observations in row $i$, $\sum_i$ is the filtered model-implied covariance matrix, and $M_i$ is the filtered mean vector.
The filtered mean vector and covariance matrix is how FIML handles missing values at $X_i$.
For example, given a model-implied mean row vector $M=(4.3, 5.3, 1.2)$ and the row $X_i=(NA, 2, 0.4)$, in which $NA$ indicates a missing value, then the filtered row mean vector is $M_i = (5.4, 1.2)$. 
The $-2\log$ of the whole data can then be calculated as
\begin{equation}
  \mathcal{L} = \sum^n_{i=1} \mathcal{L}_i
\end{equation}
The overall goodness-of-fit of the model relative to a perfect fit, meaning that all covariances are estimated, is measured by a likelihood ratio square statistic ($\chi^2$).
Therefore, should we fail to reject the null hypothesis that our model in Figure~\ref{fig:ace} is different from a perfect fitted model we have reason to assume that our genetic model fits the data.

The use of SEM allows for great flexibility and a variety of models to be estimated.
In the past few decades numerous twin studies on a variety of traits have been performed.
It not only allowed testing for the differences in the genetic architecture between the sexes but also examining how influence of genetic factors change over age.
In addition, Falconer's method is only able to approximate the broad sense heritability and is unable to distinguish between $A$ and $D$.
However, it is important to keep in mind that twin models make a few fundamental assumptions.
Indeed, twin models assume that twin pairs do not differ from the general population and that mating occurs at random.
Furthermore, it is assumed that the effect of gene-environment interactions are small and that MZ and DZ twin pairs share their corresponding environment to the same degree, also called equal environment assumption (EEA)~\cite{Rijsdijk2002}.

Especially the EEA has come under more closer scrutiny in previous research~\cite{Martin1997}. 
Indeed, various studies have shown that MZ twins have higher correlations across a variety of environments than DZ twins~\cite{Loehlin1976}.
Thus suggesting a violation of the underlying assumption.
Nevertheless, these environments often fail to have an effect on behavioral outcomes~\cite{Lytton1977}.
Furthermore, a number of statistical tests, examining the EEA violations, were unable to detect any major violations~\cite{Rijsdijk2002,Tuvblad2011a,Freitag2010,Derks2006}.
Thus there are strong indication that the assumptions which underline twin modeling hold.

Despite the numerous benefits of twin modeling, new advances in molecular technology has shifted research towards the identification of specific genetic loci.
In the following section I will outline the basics methods applied to molecular based association studies.
This will include a description of \acrfull{gwas} as well rare variant tests.

\section{\acrfull{gwas}}
\label{sec:gwas}

\acrfull{gwas} investigate a set of genetic variants across different individual in order to identify genetic loci associated with a certain trait.
Commonly these genetic variants are identified using DNA microarrays.
These microarrays are able to detect polymorphism within a set of individuals.
Specially, GWASs typically focus on \acrfull{snp}.
SNPs are variations within the genome at specific positions and may underly differences in traits and disease susceptibility. 
For example, the replacement of the nucleotide cytosine (C) with thymine (T) at a certain position within a stretch of DNA is considered a \acrfull{snp}.
Thus if one type of variant (also called allele) at a specific loci is significantly more frequent in cases than in controls, one speaks of an association.  

\subsection{Association Test}
\label{sub:association_test}

The association between a SNP $g$ and a trait $y$, as well as additional $p$ covariates $\bm{U}$, of an individual $i$ can be expressed as a generalized linear regression model for a continuous or binary phenotype:
\begin{equation}
  g(E(y_i)) = \beta_0 + \beta_1g_i + \bm{\beta_u}\bm{U_i'}
\end{equation}
in which $\beta_0$ is the intercept (commonly ignored in GWAS settings) and $\beta_1$ the regression coefficient of a particular SNP\@.
The vector $\bm{\beta_u}$ of size $1\times p$ are the regression coefficients of $p$ covariates to adjust for potential confounding factors.
Possible confounding factors are population stratification, sex, genotyping chip, and others.
The link function $g(.)$ is a logit function for binary traits, while for quantitative traits no transformation is used (identity link function). 

Genotypes of each SNP can be organized to represent dominant, recessive, multiplicative, as well as additive models~\cite{Bush2012}.
For example, assuming at a given position the two alleles are \textit{A} and \textit{a}.
In a dominant model (for \textit{A}) disease risk increases for having one or two copies of \textit{A} over no copies of \textit{A}.
Thus the risk $k$ is the same for \textit{Aa} and \textit{AA}.
In contrast, a recessive model (for \textit{A}) requires at least two copies of the risk allele \textit{A}.
The multiplicative model (for \textit{A}) expects a squared increase in risk.
If the risk of having the \textit{A} allele is $k$ then the risk of two copies of the same allele is $k^2$.
An additive model assumes a linear increase in risk for each additional allele copy.
Thus if the risk of \textit{Aa} is $k$ then the risk doubles ($2k$) for \textit{AA}. 
Despite these different models, GWAS commonly uses an additive model only since it has good statistical power to detect dominant effects as well.
Nevertheless, an additive model has reduced power for potential recessive effects~\cite{Bush2012}.

A statistical significant association between a allele and a specific trait does not necessary suggest a causal relationship.
Indeed, it is important to point out that loci are not necessary independent from each other, but can be in \acrfull{ld} with each other.

\subsection{Linkage Disequilibrium}
\label{sub:linkage_disequilibrium}

LD is `the nonrandom association of alleles at different loci'~\cite{Slatkin2008} and forms a marker of the population genetic mechanism that is at play within our genome.
For example, two loci are said to be in high LD when allele $A$ at one loci co-occurs with allele $B$ at a different loci at a higher frequency then one would expect if the two loci were independent.
Hence the level of LD can be quantified as $D_{AB}=p_{AB} - p_{A}p_{B}$ in which in which $p_{AB}$ is the frequency that $A$ and $B$ occurs together wile $p_A$ and $p_B$ is the frequency of $A$ and $B$, respectively.
If $D_{AB} \neq 0$, A and B are said to be in linkage disequilibrium, otherwise the two alleles are in linkage equilibrium ($D_{AB}=0$).
Nevertheless, $D_{AB}$ depends on the frequencies of the alleles in questions and is therefore not always convenient.
Therefore, LD between two loci is commonly measured in two different ways. 
That is $D'$ and $r^2$.
\citet{Lewontin1964} suggested to use
\begin{equation}\label{eq:dprime}
  D' = D/D_{\min}
\end{equation}
where 
\begin{equation*}
  D_{\min}= \begin{cases}
    \max\{-p_A p_B,\,-(1-p_A)(1-p_B)\} & \text{when } D < 0\\
    \min\{p_A (1-p_B),\,(1-p_A) p_B\} & \text{when } D > 0
  \end{cases} 
\end{equation*}
Alternatively, one can also use the correlation coefficient $r^2$ between the two loci 
\begin{equation}\label{eq:r2}
  r^2=\frac{D^2}{p_A(1-p_A)p_B (1-p_B)}
\end{equation}
An important consequence for association studies is that when an association between a trait and an allele is found, that allele is unlikely to be the actual causal SNP\@.
An association between a SNP and a trait can arise for multiple reasons.
First, the association could represent the true effect and the particular SNP has a causal relationship on the trait in question.
Second, and more likely, the associated SNP is a proxy of the causal SNP since both are in high \acrshort{ld}.
Third, the association is a random fluctuation within the sample, and 
fourth, the association is due to confounding errors such as population stratification or genotyping errors.

This makes the identification of causal variants as well as the design of GWASs difficult.
However, while the underlying LD structure of the human genome is relatively complicated one can estimate statistical power analytically in a simple additive model with equal cases and controls.
Given an observed genetic marker and an unobserved causal variant, then
\begin{equation}\label{eq:causal}
  E[\chi^2] \prop N\gamma^2p(1-p)r^2
\end{equation}
in which $\chi^2$ is the chi-square statistic for a given marker, $N$ is the number of cases and controls, $\gamma$ is the effect size, $p$ is the frequency of the risk variant, and $r^2$ the LD between the marker and the causal variant.

Therefore, variants will low LD to the causal variants have less statistical power.
Indeed, equation~\ref{eq:causal} demonstrates that when given a small effect ($N\gamma^2p(1-p) < 10$) even a large LD ($0.8  < r^2 \leq 1$) results in inadequate statistical power.
This points to an important limitation of GWAS.
While common variants (usually alleles with a frequency of $>5\%$) have often considerable LD with other loci, LD across rare variants is small.
Therefore, considerable reducing statistical power of single rare variant associations.
In addition, DNA microarrays commonly only assess common SNPs.
Hence most GWAS do not aim to identify rare variant associations, but focus only on common genetic loci.

\subsection{Common Disease Common Variant Hypothesis}
\label{sub:common_versus_rare_genetic_variants}

Association analysis of common genetic variants is usually only applied to investigate potential genetic markers of common traits and disorders, while different strategies are applied for rare diseases.
Indeed, assessments of families whose members are disproportional affected with a rare genetic disorder, such as Huntington's disease or cystic fibrosis, were able to identify a number of disease-causing variants~\cite{Kerem1989}.
However, while this method was initially successful with a number of other rare disorders, common disorders, such as heart disease, psychiatric disorders, as well as others, fared not that well,  
implying that common and rare disorders have a different genetic architecture~\cite{Hirschhorn2005a}.
This resulted in the conceptualization of the common disease common variant hypothesis.
The common disease common variant hypothesis suggests that common disorders are affected by genetic variations which are also common in the population~\cite{Schork2010}.
This hypothesis, while simplistic, has some profound implications.

Importantly it is unlikely that common variants will have a high penetrance and are the lone disease-causing mutations.
For example, a common variant with a frequency of 45\% that directly causes a disorder would mean that also 45\% of the population would be affected by the disease.
This is unlikely to be the case and it is more likely that a given SNP only has a small effect on the disease.
This in turn also implies that multiple common variants affect a common disorder.
For example, twin studies have estimated the heritability of aggressive behavior at 50\%.
If a single SNP has only a small effect on the phenotype, then the total genetic risk must be distributed across multiple common genetic variants.
Figure~\ref{fig:rare_comon} displays the spectrum of genetic affects and allele frequency.
\begin{figure}[htpb]
  \centering
  \includegraphics[width=0.8\linewidth]{{introduction/figure/journal.pcbi.1002822.g001}.png}
  \caption[Spectrum of Disease Allele Effects]{Spectrum of Disease Allele Effects~\cite{Bush2012}.}\label{fig:rare_comon}
\end{figure}

Overall, the common disease common variant hypothesis has been tested numerous times~\cite{Bush2012}.
Most common SNPs identified in the last 10 years are of small effect and most common disorders have multiple risk alleles~\cite{Welter2014,Schork2010}, suggesting that the hypothesis holds true. 
However, this does not imply that all genetic contributions to a common disorder are due to common variants alone.
Indeed, there have been some successful genetic associations of common variants in rare disorders.
For example,~\cite{Garcia-Barcelo2009a} identified 2 common SNPs associated with Hirschsprung's disease, a rare congenital disorder (2.8 per 10,000 births).

\subsection{Population Stratification}
\label{ssec:population_stratification}

Population stratification takes place when differences in the frequencies of alleles among cases and controls are not due to a causal relationship between the SNP and the trait.
Rather, they are caused by ancestral differences across populations.
An association is affected by population stratification if the trait is more prevalent in one population while the allele frequencies vary across the populations.

Commonly one can account for population stratification by the usage of \acrfull{pca}.
PCA is a procedure which transforms a set of correlated variables into a set of linear uncorrelated ones, called principal components (\acrshort{pc}).
The number of PC can be smaller or equal to that of the number of initial variables and the first PC accounts for most of the variability in the set of correlated variables.
Each following PC explains the most variance constrained that it is orthogonal to all previous components.

Using PCA on a matrix of individuals by SNPs, in which each cell represents the count of minor alleles, results in a set of PCs which explain the genetic variation within the sample.
Given the sample is a mixture out of multiple populations with different ancestry the computed PCs will often have geographic interpretation.
Thus including PCs into the association model will adjust for population stratification arising due to differences in allele frequencies and disease prevalence.

However, PCA is not the only method to adjust for population stratification.
Indeed, other methods include the genomic control factor (see Section~\ref{sub:conditional_false_discovery_rate}), linear mixed models and family based studies.

\subsection{Multiple Testing}
\label{ssec:multiple_testing}

Testing a numerous genetic variants without adjusting the significance threshold $\alpha$ results in a number of falsely associated variants.
Therefore, adjustment of the significance threshold is necessary.
For example, one could simply adjust $\alpha$ by the number of tests performed (Bonferroni threshold).
However, this would result in an overly conservative threshold and in a number of false negative associations~\cite{Benjamini1995} since computed test statistics are not independent due to LD\@.
Indeed, ~\citet{Peer2008} estimated, based on data from the International Haplotype Map Consortium, the number of independent tests to be one million in Europeans and two million in African populations.
Therefore, most GWAS in Europeans have used a threshold of $5\times 10^{-8}$.
However, due to the introduction of larger sample sizes as well as better technology we are able to genotype variants with lower allele frequency.
This requires more stringent adjustment of the GWAS significant threshold since it also increases the number of independent tests.
Hence~\citet{Fadista2016} recently suggested to use $3\times10^{-8}$, $2\times10^{-8}$, $1\times10^{-8}$ when including variants with $MAF\ge1\%$, $MAF\ge0.5\%$, and $MAF\ge0.1\%$, respectively.

\acrshort{gwas} are useful in identifying molecular markers for traits and diseases.
While there are multiple possible confounding factors, such as population stratification, methods have been developed to approach these problems successfully.


\section{SNP Heritability and Genetic Correlation}
\label{sec:heritability_and_genetic_correlation}

As already described above, studies on twins were able to assess the heritability of traits, or the proportion of variance due to additive genetic effects, by considering the MZ and DZ twin correlations.
Interestingly, a number of methods have also been developed to assess narrow sense heritability, or the additive genetic effect from genotyped data.
Several methods have been proposed in the past, most notably \acrfull{gcta} and LD-score regression.

\subsection{\acrfull{gcta}}
\label{sub:gcta}

GCTA uses a mixed linear model to  fit the effect of all SNPs by making use of the genetic relationship matrix of all included subjects~\cite{Yang2011}.
If $\textbf{A}$ is the genetic relatedness matrix then
\begin{equation}
  y = X\beta + g + \epsilon \text{ with } var(y) = V = A\sigma^2_g + I\sigma^2_\epsilon
\end{equation}
in which $y$ is the phenotype and $\beta$ are the estimated effect sizes of all covariates and the total genetic effect $g$ for each individual is $g \sim N(0, A\sigma^2_g)$.
GCTA is then able to estimate the variance explained by all SNPs, $\sigma^2_g$, by restricted maximum likelihood.
One can extend this model to bivariate linear mixed models to estimate the genetic correlation between two traits as well.
If $y_1 = X_1\beta_1 + g_1 + \epsilon_1$ for trait 1 and $y_2= X_2\beta_2 + g_2 + \epsilon_2$ for trait 2 then the variance-covariance matrix $V$ is
\begin{equation}
  V = 
  \begin{pmatrix}
    Z_1AZ_1'\sigma^2_{g1} + I\sigma^2_{\epsilon 1} & Z_1AZ_2'\sigma^2_{g_1g_2} \\
    Z_2AZ_1'\sigma^2_{g_1g_2} & Z_2AZ_2'\sigma^2_{g2} + I\sigma^2_{\epsilon 2}
  \end{pmatrix}
\end{equation}
in which $X$ and $Z$ are the incidence matrices for the effects of $\beta$ and $g$.
However, GCTA requires considerable computational power as well as the availability of the raw genotype data.
Hence, LD-score regression has been developed to estimate SNP heritability on summary statistics only.

\subsection{LD-score Regression}
\label{sub:ld_score_regression}

LD-score regression makes use of the previously outlined LD among tagged and causal SNPs.
Test statistics of SNPs in high LD with the causal variant will be elevated proportional to their LD\@.
Thus the more genetic variation a SNP tags the higher the probability that it will tag a causal variant.
LD-score regression makes use of this relationship and regresses the estimated $\chi^2$ from the association study on the LD-score, which measures the overall LD of variant $j = 1, \ldots, M$ as $\ell_j = \sum^M_{k=1} r^2_{jk}$. 
The slope of this regression can then be interpreted as an estimate of heritability~\cite{Bulik-Sullivan2015}.
Similarly, if we replace the $\chi^2$ of a single study by the product of the z-scores of two separate studies and regress it onto $\ell_j \sqrt{N_{1}N_{2}}$, which $N_1$ and $N_2$ represent the corresponding sample sizes of trait one and two, the slope can be interpreted as the genetic covariance between trait 1 and 2~\cite{Bulik-Sullivan2015a}.

\subsection{The Missing Heritability Problem}
\label{sub:missing_heritability}

Interestingly, the variance explained by known genetic variants and the heritability estimations from twin studies show considerable discrepancy.
This is commonly called the `Missing Heritability Problem'~\cite{Vineis2010} and a  number of reasons have been suggested for the discrepancy between estimates in twin studies and those in GWAS\@.

It has been suggested that the missing heritability can be found in variants with smaller effects.
Indeed, current GWASs have often not the necessary statistical power to detect variants with small effect sizes and an increase in sample size has resulted in a number of newly identified variants across different disorders \cite{Kathiresan2009,Ahmed2009,Zeggini2008}.
\citet{Manolio2009} suggested that natural selection might be responsible for keeping effect sizes of complex traits low by removing variants with larger effects.
Therefore decreasing efficient detection in GWASs.

Importantly, GWASs typically only consider common variants and rare variants might account for the missing heritability.
While most rare variants have little or no effect on traits, some rare variants have very large effects.
Indeed, a study on height found that while most common variants only had small effects, some rare genetic variants resulted in a large increase in height of up to $2cm$~\cite{Marouli2017}.
This would indicate that rare variants can have a profound effect on common traits, suggesting that heritability estimates using common variants alone might be biased downward.
Furthermore past studies might have only incompletely identified causal variants.
A number of genes which harbour common variants of medium effect might also include a number of rare variants of large effects~\cite{Manolio2009}. 

Also epistasis is hardly tested in most studies and could account for the missing heritability.
Indeed complex gene-gene interaction have been shown in a number of experimental studies in  animals~\cite{Zuk24012012}.
Therefore, suggesting that epistatic effects might play a major role in humans as well.
However, models which include gene-gene or even gene-gene-gene and higher order interactions are very computational intensive and require large datasets~\cite{Lippert2013}.
Furthermore, one would expect that the effect of very strong gene-gene interaction would also be partially present in the main effects of the corresponding loci.

In addition to gene-gene interaction, rare and low effect variants one also needs to consider structural variations.
Copy number variations (CNV), such as insertions and deletions, and copy neutral variations (inversions and translocations) might contribute to the missing heritability problem~\cite{Zarrei2015}.
However, most current studies do not examine structural variations and only recently methods have been developed to explore these variations.
Unfortunately current algorithms show large inconsistencies in detected structural variations~\cite{Pirooznia2015}.
Indeed,in their review~\citet{Li2013a} pointed out that the high signal-to-noise ratio as well as the short reads in next-generation sequencing technology displays a serious challenge to current methods.
Hence it remains unclear if structural variations might help to explain the missing heritability.

At last it is is also possible that assumptions in twin studies might be violated and estimates are too high.
In particular, studies on twins assume that shared environmental factors influence MZ and DZ twins to the same extent.
One can argue that MZ twins are treated by parents, teachers, and peers differently resulting in a potential violation of the this equal environments assumption. 
However, while previous research suggest that the equal environment assumption might not be strictly valid, the induced bias is likely to be small~\cite{Derks2006,Felson2014}

While a single reason for the missing heritability seems unlikely it is still an ongoing research objective to account for the differences.

\subsection{Genetic Correlations}
\label{sub:genetic_correlations_method}

The development of both LD-score regression and GCTA have enabled recent research to uncover the genetic correlations among a variety of different traits, even when the two traits are measured on different people.
However, genetic correlation can arise from a multitude of different sources.
Figure~\ref{fig:genetic_correlation} shows 4 different ways genetic correlation can arise.
First and foremost, genetic correlation can arise if two traits are caused by the same genetic factors (see Figure~\ref{fig:pleiotropy}).
Second, a genetic factor  causes phenotype 1 and that phenotype can in turn cause phenotype 2 (see mediated pleiotropy in Figure~\ref{fig:mediated_pleiotropy}).
Third, genetic correlation can also arise from assortative mating as shown in Figure~\ref{fig:assortative_mating}.
Assortative mating is a non-random mating pattern within a population and can lead to a genetic correlation between two traits.
For example, consider two traits which share no initial causal variant.
Trait 1 is desirable in males while trait 2 is desirable in females, hence resulting in an increase in offspring who harbour the causal variants of both traits.
Over a few generation this will result in LD between causal variants of trait 1 and 2 despite sharing no initial causal SNPs, resulting in a genetic correlation. 
Fourth, also parental effect can result in genetic corrections as displayed in Figure~\ref{fig:parental_effects}.
Specifically, genetic components cause trait $1$ in the parents which influences the child's environment which in turn results in trait 2. 
Nevertheless, the genetic correlations estimated by LD-score and GCTA are unable to distinguish between the possible sources of genetic correlations.

\begin{figure}[htp]
  \begin{subfigure}[t]{0.4\textwidth}
    \centering
    \resizebox{0.5\linewidth}{!}{\input{introduction/figure/genetic_correlation/pleiotropy.tex}} 
    \caption{Pleiotropy}\label{fig:pleiotropy}
  \end{subfigure}
  \begin{subfigure}[t]{0.4\textwidth}
    \centering
    \resizebox{0.5\linewidth}{!}{\input{introduction/figure/genetic_correlation/mediated_pleiotropy.tex}} 
    \caption{Mediated Pleiotropy}\label{fig:mediated_pleiotropy}
  \end{subfigure}
  \begin{subfigure}[t]{0.4\textwidth}
    \centering
    \resizebox{0.6\linewidth}{!}{\input{introduction/figure/genetic_correlation/assortative_mating.tex}} 
    \caption{Assortative Mating}\label{fig:assortative_mating}
  \end{subfigure}
  \begin{subfigure}[t]{0.4\textwidth}
    \centering
    \resizebox{0.6\linewidth}{!}{\input{introduction/figure/genetic_correlation/parental_effects.tex}}
    \caption{Parental Effects}\label{fig:parental_effects}
  \end{subfigure}
  \caption[Sources of Genetic Correlations]{Different sources of genetic correlation according to~\citet{Pickrell2016}}\label{fig:genetic_correlation}
\end{figure}

To conclude, during the last few years large gains have been made in fostering our understanding of heritability and genetic correlations with the development of GCTA and LD-score regression.
While these tools are able to estimate heritability and genetic correlations of a number of traits it remains difficult to distinguish between different sources of genetic correlations.
Furthermore, GCTA and LD-score regression do not take rare variants or structural variations into account, thus are suffering from similar limitations as typical GWASs.

\section{Association Studies on Rare Variants}
\label{sec:association_studies_on_rare_varitants}

A possible suspect for the missing heritability are rare variants.
Rare variants,  variants with a \acrfull{maf} of 1\% or lower, have been suggested to explain the bulk of missing heritability~\cite{Jiang2013,Li2009a}.
Rare variants are commonly not accessible via micro array chips but only via the more cost intensive sequencing.
However, the drop in sequencing costs has allowed us to conduct whole-exome and whole genome association studies of rare variants~\cite{Goodwin2016}.
In contrast to GWAS, single variant associations are largely unfeasible, unless sample size is very large~\cite{Lee2014}.
Hence, considerable effort has been made to develop and deploy statistical methods to improve statistical power of rare variant association studies~\cite{Morris2010,Zeng2014,Daye2012,Manuscript2013}.
Instead of testing individual genetic markers most statistical tests evaluate the combined effect of multiple genetic variations in a biologically-relevant region, such as a gene.
In general, one can divide such approaches into burden and variance component tests.
I will first introduce the general statistical model for the two tests.
Following, I will outline two commonly used classes of tests and evaluate their benefits and drawbacks.

Assuming that $y_i$ for subject $i$ with mean $\mu_i$ follows a distribution in the quasi-likelihood family~\cite{Lee2014} with $n$ subjects in a region with $m$ variants, then
\begin{equation}
  h(\mu_i) = \alpha_0 + \alpha'X_i +\beta'G_i
\end{equation}
in which $h(\mu) = \mu$ or $h(\mu) = logit(\mu)$.
The regression coefficients of the covariates and allele counts are $\alpha = (\alpha_1, \ldots, \alpha_q)$ as well as $\beta = (\beta_1, \ldots, \beta_m)$, respectively.
The covariates are denoted as $X_i = (X_{i1}, \ldots, X_{iq})'$ and the allele counts as $G_{i1}, \ldots, G_{im}$.
The score statistic of the marginal model for variant $j$ is then
\begin{equation}
  S_j = \sum^n_{i=1} G_{ij}(y_i-\hat{\mu_i})
\end{equation}
where $\hat{\mu_i}$ is the estimated mean under $H_0: \beta = 0 $ and is obtained by $h(\mu_i) = \alpha_0 + \alpha'X_i$.

\subsection{Burden Test}
\label{sub:burden_test}

The simplest approach, called the burden test, tests the weighted sum of computed scores:
\begin{equation}\label{eq:burden}
  Q = {(\sum^{m}_{j=1} w_{j} S_{j})}^2
\end{equation}
in which $w_j$ is the weight for variant $j$.
Weights can be define by functional annotations, allele frequency, or other means.
The test assumes that all variants  have the same direction of effect.
This is a rather strong assumption and violations result in a loss in statistical power~\cite{Derkach2013a}.

\subsection{Variance Components Tests}
\label{sub:variance_component_tests}
In contrast to burden tests, variance-components tests evaluate the distribution of effects within a certain genomic region.
The most prominent member of this test family is \acrfull{skat}~\cite{Wu2011}.
SKAT assumes that $\beta_j\sim N(0,w_j\tau)$ and tests for $H_0: \tau = 0$ with a variance-components score test.
The test statistic is defined as
\begin{equation}\label{eq:skat}
  Q = \sum^{m}_{j=1} w_{j}^2 S_{j}^2
\end{equation}
The test is robust to groupings of protective and damaging effects within the same region.
However,  SKAT suffers from a reduction in statistical power in cases of high proportions of causal variants of the same direction, as compared to the burden test~\cite{Derkach2013a}.

To summarise, variance-components tests are generally more powerful than burden tests if a region has many non-causal variants or when the effects of a genomic region are bi-directional.
In contrast, burden tests perform better in scenarios where most causal variants have the same direction of effect.
This has led to the development of omnibus tests to combine burden and variance component tests, most notably SKAT-O~\cite{Lee2012}.

\section{Mendelian Randomization}
\label{sec:joint_association_study}

\acrfull{mr} allows  inferring potential causal effects from observational data in the presence of confounding factors. 
It allows us to assess whether a specific risk factor (exposure) has a causal effect on a disease (outcome).
MR makes use of measured variation in genetic variants with known association to a modifiable exposure, also called instrument.
Thus it assumes that certain genetic variants are associated with the exposure, and not with the outcome, except through the exposure.
Commonly, genetic variants with well known effects on the exposure are used and can be seen as a natural randomized control trial since alleles are passed randomly from parents to offspring.
MR is based on a number of assumptions, most importantly that there is no direct relation between genetic variant and outcome as well as any other confounder.
However, the use of single variants within an MR often results in underpowered studies~\cite{Bowden2015} since the effect of an given common SNP on any phenotype is usually small.
This has led to the desire to use multiple genetic variants in order to improve statistical power to estimate causal effects between exposure and outcome.


\subsection{General Methodology}
\label{sub:General_Methedology}

Assume $J$ variants in $n$ subjects (indexed by $i$) were measured ($G_{i1}, G_{i2}, \ldots , G_{iJ}$),
an exposure $X_i$ ,as well as an outcome $Y_i$.
Further, potential confounders $U_i$ are unknown. 
Within the causal model of MR the exposure is a function of the genetic variant, confounder, as well as an independent error, $\epsilon_i^X$. 
Furthermore, $\gamma_j$ represents the effect of each variant $j$ on the exposure.
The outcome, on the other hand, is the result of the linear function of the genetic variants, the exposure, the confounder, as well as an error term ($\epsilon_i^Y$).
Then the estimate of the causal effect between exposure and outcome is $\beta$, while $\alpha_j$ represents the undesired but potential direct effect between the genetic variant $j$ on the outcome:
\begin{equation} \label{eq:rm_basic}
  \begin{split}
    X_i &= \sum^J_{j=1} \gamma_jG_{ij} + U_i + \epsilon_i^X \\
    Y_i &= \sum^J_{j=1} \alpha_jG_{ij} + \beta X_i + U_i + \epsilon_i^Y \\
  \end{split}
\end{equation}
These assumed relationships of this causal model are displayed in Figure~\ref{fig:causal}.
\begin{figure}[!h]
  \centering
  \resizebox{0.5\textwidth}{!}{\input{ukb_psychiatric/figures/causalilty.tex}}
  \caption[Causal Model]{Causal Model.
    Given a genetic variant $G_j$ influences the exposure $X$, it can be used as an instrumental variable to investigate the causal effect of exposure $X$ on the outcome $Y$.
    However,this model assumes that the instrumental variable $G_j$ influences the outcome $Y$ only via the exposure $X$.
    Hence assuming that $\alpha_j=0$, $\gamma_j\neq0$ and that $G_j$ does not influence $Y$ via a third variable $U$. 
    The dotted lines indicate potential assumptions violations.
  }\label{fig:causal}
\end{figure}
Should $G_j$ be independent of confounder $U$,
as well as associated with exposure $X$ and independent of outcome $y$ conditional on $X$, then variant $j$ is a valid instrument for $X$.

The reduced-form equation~\cite{Bowden2015} of Equation~\ref{eq:rm_basic}, relating outcome with $G_j$, can be written as
\begin{equation}
	\begin{split}
		Y_i &= \Gamma_j G_{ij} + \epsilon_{ij}^{'Y} \\
		&= (\alpha_j + \beta\gamma_j)G_{ij} + \epsilon_{ij}^{'Y}
	\end{split}
\end{equation}
One can then estimate the causal effect $\beta$ with the help of the Wald method~\cite{Wald1940},
by dividing the effect of variant $j$ on the outcome (denoted as $\hat{\Gamma_j}$) by the effect on the exposure (denoted as $\hat{\gamma_j}$).
Assuming that $\alpha=0$, then the causal effect $\beta$ is
\begin{equation} \label{eq:causal_estiamte}
	\beta = \frac{\beta\gamma_j}{\gamma_j}= \frac{\Gamma_j}{\gamma_j}
\end{equation}

However, single variants often have inadequate statistical power, so one can extend Equation~\ref{eq:causal_estiamte} to multiple variants as a weighted average of multiple ratio estimates across uncorrelated genetic variants~\cite{Bowden2015}:
\begin{equation} \label{eq:IVW}
  \frac{\sum^J_{j=1} \hat{\gamma}_j^2\sigma_{Yj}^{-2} \hat{\beta}_j}
  {\sum^J_{j=1} \hat{\gamma}_j^2\sigma_{Yj}^{-2}}
\end{equation}
in which $\hat{\beta}_j = \frac{\hat{\Gamma}_j}{\hat{\gamma}_j}$ and the weight $\sigma_{Yj}$ is the standard error of the outcome on the $jth$ variant.

Often one cannot assume that $\alpha_j = 0$.
In this case the Wald ratio estimate of variant $j$ will equal the true causal effect plus the error $\frac{\alpha_j}{\gamma_j}$~\cite{Bowden2015}. 
Hence in the presence of $\alpha_j \neq 0$, Equation~\ref{eq:IVW} is re-written as
\begin{equation} \label{eq:TSLSbias}
  \beta + \frac{\sum^J_{j=1} \gamma_j^2\sigma_{Y_j}^{-2} \alpha_j}
  {\sum^J_{j=1} \gamma_j^2\sigma_{Y_j}^{-2}} = \beta + Bias(\alpha, \gamma)
\end{equation}
Importantly, this implies that the assumed independence between genetic variants with the outcome $y$ conditional on $X$ holds if the bias term has a mean of zero.
Based on these general assumptions and characteristics of Mendelian randomization, numerous different methods have been proposed.

\subsection{MR Methods}
\label{sub:Used_Methods}

Due to differences in robustness in regards to various potential assumption violations~\citet{Burgess2016}, it is recommended that several different MR methods be used in order to assess potential causal relationships.
The estimated causal effects can then be judged over all  applied models.
Further, a sensitivity analysis of each MR analysis can be performed to investigate validity of the underlying assumptions~\cite{Burgess2016}.
A sensitivity analysis investigates the validity of the causal inference by MR since it is implausible that all selected SNPs satisfy the instrumental variable assumption~\cite{Burgess2016}.
This is commonly done by assessing directional pleiotropy via funnel plots, investigating heterogeneity, as well as testing the reverse direction of causality and linearity.

There are five commonly used MR methods.
That is, the \acrfull{ivm}, the weighted median method~\cite{Bowden2016}, as well as MR-Egger regression~\cite{Bowden2015}.
Further a number of applied classical meta analysis methods with fixed~\cite{Nelson2015a} and random effects~\cite{Ahmad2015a} can be applied.
Overall, these methods differ in their robustness to pleiotropy (or the effect non-null effect of $\alpha_j$) as well as statistical power.

The IVM has been described already in the previous section (see Equation~\ref{eq:IVW}).
The method, while having greater statistical power than other methods, assumes that all used variants are valid instruments.
Thus IVM is especially susceptible to presence of pleiotropy~\cite{Burgess2015b}.
In contrast, the weighted median method first estimates the causal effect for each variant separately weighted by the inverse variance. 
Following, estimates are then ranked and the median of this distribution is used to represent the estimated causal effect between exposure and outcome.
This simple approach has the benefit that if at least 50\% of variants are valid instruments it will give consistent causal estimates.
However, this comes with a lose in precision~\cite{Bowden2015}.

MR-Egger is a newer method which relaxes the assumption of $\alpha_j=0$, instead  assuming that the correlation between $\alpha_j$ and $\gamma_j$ is $0$.
Thus MR-Egger relaxes the pleiotropic assumptions and allows variants to exhibit pleiotropic effects as long as this effect, across all used instrument, equals to zero.
Under this assumption, the bias (see Equation~\ref{eq:TSLSbias}) is inversely proportional to $\gamma_j$ and variants with stronger instrument strength (large $\gamma_j$) will on average be closer to the true causal effect.
MR-egger makes use of this by regressing $\hat{\Gamma}_j$ on $\hat{\gamma}_j$:
\begin{equation}\label{eq:egger}
  \hat{\Gamma}_j = \beta_{0E} + \beta_{E} \hat{\gamma}_j
\end{equation}
Interestingly, $H_0$ of the intercept $\beta_E$ then gives an indication of the overall directional pleiotropy.
Thus MR-egger uses a relatively relaxed assumption but comes with the cost of  considerably lower statistical power~\cite{Bowden2015}.

Finally, a fixed meta-analysis was used which assumes that the estimated effects $\beta_j$ are equal across assessed variants~\cite{Burgess2015b}.
However, this might not be the case in practice since it assumes that all selected instruments are valid.
In addition, variants might have different effects on the outcome which is not exclusively directed thought the exposure. 
In contrast, mixed-effect models do not assume equal effect across genetic variants~\cite{Burgess2015b}.
Specifically, in contrast to fixed effect model where the effect of each instrument $\beta_j$ is modeled as normally distributed with a  mean $\beta_j = \beta$ and variance $\sigma_{Y_j}^2$, a mixed-effect model assumes additionally that also $\beta_j$ is normally distributed with a mean of $\mu_\beta$ with variance $\phi^2$.

\bigskip
To conclude, I have outlined various statistical methods to investigate the genetic contribution of aggressive behavior.
I have described the commonly applied twin model to estimate the contribution of genetic and environmental effects.
Further, I outlined the principles of genome wide association studies as well as the use of GCTA and LD-score to estimate the narrow sense heritability from common SNPs.
In addition, I have described principles and common methods used in Mendelian Randomization studies.
Finally, I have described two commonly-used rare variant tests as well as their pros and cons.

In the next chapter I will present an investigation of the longitudinal heritability of childhood aggression with the use of two large twin cohorts. 
